# 当前总结逻辑梳理（v2/v3）

> 更新时间：2026-02-26
> 范围：`chat_app_server_rs` 现有实现（已接入 shared summary engine + bisect）

## 1. 总结是怎么触发的

### 1.1 统一引擎内部触发判定（Proactive）
`summary::engine::detect_proactive_trigger` 会在 `SummaryTrigger::Proactive` 下判定：
- 消息条数达到阈值：`messages.len() >= message_limit`
- 或估算 token 达到阈值：`estimated_tokens >= max_context_tokens`

对应代码：
- `chat_app_server_rs/src/services/summary/engine.rs:33`

### 1.2 v2 的“主动总结”触发路径
v2 在发送模型请求前，会先做一层“增量窗口”判定：
- 先找“上次摘要锚点”或“本轮用户锚点”
- 只统计这段 delta 的条数/token
- 满足任一条件就触发总结：
  - `delta_count >= SUMMARY_MESSAGE_LIMIT`
  - 或 `delta_tokens >= SUMMARY_MAX_CONTEXT_TOKENS`

满足后调用 `maybe_summarize_in_memory(...)`，并通过 `SummaryOverrides` 强制引擎立即总结（`message_limit=1`, `max_context_tokens=1`, `keep_last_n=0`）。

对应代码：
- 触发判定：`chat_app_server_rs/src/services/v2/ai_client/mod.rs:281`
- 调用总结：`chat_app_server_rs/src/services/v2/ai_client/mod.rs:310`

### 1.3 v3 的“主动总结”触发路径
v3 在 **stateless 模式** 下，每轮请求前调用：
- `maybe_proactive_summarize_stateless_input(...)`
- 内部把 input items 转回 chat messages 后，交给 shared engine 的 `maybe_summarize`
- 是否总结由引擎统一判定（message/token 阈值）

对应代码：
- 调用点：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:299`
- 主动总结函数：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:818`

### 1.4 超窗后的“被动总结重试”（OverflowRetry）
当主请求报 context overflow（`context_length_exceeded` 等）时：
- v2: `try_compact_for_token_limit(...)` 先尝试 `retry_after_context_overflow_in_memory(...)`
- v3: `try_summary_after_context_overflow(...)` 先尝试 `retry_after_context_overflow_with_engine(...)`
- 引擎内部会把 `keep_last_n` 强制设为 0，优先做“全量压缩后重试”

对应代码：
- 引擎重试入口：`chat_app_server_rs/src/services/summary/engine.rs:181`
- v2 溢出总结重试：`chat_app_server_rs/src/services/v2/ai_client/mod.rs:568`
- v3 溢出总结重试：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:868`

### 1.5 v3 的二级兜底（保留）
如果“超窗总结重试”仍未产出可用输入，v3 会继续执行历史窗口减半：
- `history_limit = history_limit / 2`，直到不能再减

对应代码：
- 减半策略：`chat_app_server_rs/src/services/v3/ai_client/prev_context.rs:55`
- 使用位置：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:506`

---

## 2. 总结是怎么做出来的（算法）

统一在 `summary::engine`：

1) 先准备输入：
- 根据 `keep_last_n` 保留尾部消息，不参与总结
- 且保留边界会避免从 `tool` 消息中间硬切（向前回退）

2) 直接请求总结模型；如果成功，返回 `SummaryResult`

3) 如果失败且是 context overflow，并且 `SUMMARY_BISECT_ENABLED=true`：
- 按边界规则二分（避免切在 `assistant(tool_calls)` 与 `tool` 输出之间）
- 递归总结左右两段
- 再对左右摘要做归并总结（pairwise merge）

4) 终止保护：
- 达到 `SUMMARY_BISECT_MAX_DEPTH`
- 或消息数低于 `SUMMARY_BISECT_MIN_MESSAGES`
- 或无法再合法切分
- 则进入 `force_truncated_summary`，标记 `truncated=true`

对应代码：
- 输入准备：`chat_app_server_rs/src/services/summary/engine.rs:69`
- `keep_last_n` 边界处理：`chat_app_server_rs/src/services/summary/engine.rs:49`
- 递归 bisect：`chat_app_server_rs/src/services/summary/engine.rs:217`
- split 规则：`chat_app_server_rs/src/services/summary/splitter.rs:1`

---

## 3. 总结后的内容是怎么存的

总结落库统一通过 `SummaryStore`（v2/v3 各有 adapter 实现）。

### 3.1 主摘要记录（session_summaries）
每次总结会创建一条 `session_summaries`：
- `summary_text`
- `summary_prompt`
- `model` / `temperature`
- `target_summary_tokens` / `keep_last_n`
- `message_count` / `approx_tokens`
- `first_message_id` / `last_message_id` / 对应时间
- `metadata`

其中 `metadata` 包含：
- `algorithm: "bisect_v1"`
- `trigger: "proactive" | "overflow_retry"`
- `chunk_count`
- `max_depth`
- `truncated`
- `compression_ratio`
- `input_tokens` / `output_tokens`

对应代码：
- metadata 构造：`chat_app_server_rs/src/services/summary/persist.rs:6`
- v2 持久化：`chat_app_server_rs/src/services/v2/summary_adapter.rs:70`
- v3 持久化：`chat_app_server_rs/src/services/v3/summary_adapter.rs:76`

### 3.2 摘要-消息关联（session_summary_messages）
会把“本次被总结掉的 message_id 列表”写入关联表，便于追溯来源。

对应代码：
- 链接写入：`chat_app_server_rs/src/services/v2/summary_adapter.rs:100`
- 链接写入：`chat_app_server_rs/src/services/v3/summary_adapter.rs:106`

### 3.3 兼容占位消息（messages）
同时会写一条 `messages` 里的 assistant 占位消息：
- `metadata.type = "session_summary"`
- `summary` 字段保存摘要正文
- metadata 里带 `summary_id`、`trigger`、`chunk_count` 等

这条用于旧路径兼容和回放。

对应代码：
- v2 占位写入：`chat_app_server_rs/src/services/v2/summary_adapter.rs:120`
- v3 占位写入：`chat_app_server_rs/src/services/v3/summary_adapter.rs:126`

### 3.4 一个细节
当前 **触发原因**（`message_limit` / `token_limit` / `overflow_retry`）会在事件回调里发出，但不会完整写入 DB；DB 里存的是 `trigger`（proactive/overflow_retry）。

---

## 4. 下次对话怎么取历史

### 4.1 统一历史加载入口
`get_session_history_with_summaries(session_id, limit, summary_limit)` 的行为：
1. 先取摘要表（默认 `summary_limit=2`）
2. 若有摘要，取“最后一条摘要之后”的消息（`last_message_created_at` 之后）
3. 若无摘要，按原逻辑取普通历史消息

这样可以避免重复把“已被摘要覆盖”的旧消息再次拼进上下文。

对应代码：
- 核心逻辑：`chat_app_server_rs/src/services/message_manager_common.rs:148`

### 4.2 v2 组装请求历史
v2 会把历史组装为 chat messages：
- 优先使用 `session_summaries` 里的摘要作为 `system` 消息
- 再拼接“摘要之后”的 history
- 若摘要表没有数据，则回退使用 `messages` 里 `type=session_summary` 的占位摘要
- 最后做两步修正：
  - `drop_duplicate_tail(...)`（去掉与当前请求尾部重复）
  - `ensure_tool_responses(...)`（保证 tool_call/tool_output 对齐）

对应代码：
- 历史装载：`chat_app_server_rs/src/services/v2/ai_client/mod.rs:118`
- 去重与配对：`chat_app_server_rs/src/services/v2/ai_client/history_tools.rs:26`

### 4.3 v3 组装请求历史（stateless 模式）
v3 在 stateless 模式下通过 `build_stateless_items(...)`：
- 摘要转为 `type=message role=system`
- 普通消息转为 `type=message`
- assistant tool_calls 转为 `type=function_call`
- tool 消息转为 `type=function_call_output`
- 同样支持“摘要表优先，placeholder 回退”

对应代码：
- stateless 构造：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:985`

### 4.4 v3 的 prev_id 模式
当 provider 支持 `previous_response_id` 且当前会话可用时：
- v3 会走 prev_id 增量上下文，不做 stateless 历史重建
- 一旦遇到不支持/缺失 tool_call/上下文超窗，再回落到 stateless 并触发上述历史构建与总结策略

对应代码：
- 模式判定：`chat_app_server_rs/src/services/v3/ai_client/mod.rs:182`

---

## 5. 关键配置（当前实现）

- `DYNAMIC_SUMMARY_ENABLED`
- `SUMMARY_MESSAGE_LIMIT`
- `SUMMARY_MAX_CONTEXT_TOKENS`
- `SUMMARY_KEEP_LAST_N`
- `SUMMARY_TARGET_TOKENS`
- `SUMMARY_MERGE_TARGET_TOKENS`
- `SUMMARY_BISECT_ENABLED`
- `SUMMARY_BISECT_MAX_DEPTH`
- `SUMMARY_BISECT_MIN_MESSAGES`
- `SUMMARY_RETRY_ON_CONTEXT_OVERFLOW`

默认值来源：
- `chat_app_server_rs/src/config.rs:83`
- 用户设置键：`chat_app_server_rs/src/services/user_settings.rs:7`

---

## 6. 结论（一句话版）

当前逻辑是：
- **先按阈值主动总结**，
- **超窗时优先做总结重试**（带 bisect 递归压缩），
- **仍不行再走截断/缩窗兜底**（v3 额外保留 history_limit 减半），
- 摘要以 `session_summaries + summary_message_links + messages占位` 三层落库，
- 下轮会话优先读摘要表并只拼“摘要之后”的增量历史。
